{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f375fb77-f732-46fc-8501-322da92cabd6",
   "metadata": {},
   "source": [
    "## Authors: Zhaocai Liu, Phoebe Ho\n",
    "## Purpose: This notebook is used to process GTFS data for the RouteE-BEAT Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664a8bdc-4428-4929-b2f3-2b4ee9a72111",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GTFS reference: https://gtfs.org/schedule/reference/#tripstxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704cddc-c3cb-4d52-b3e2-abfd0a060692",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1827ae66-b62e-49ee-b65d-f692a98e8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "import sqlalchemy as sql\n",
    "from mappymatch.constructs.coordinate import Coordinate\n",
    "from mappymatch.constructs.geofence import Geofence\n",
    "from mappymatch.constructs.trace import Trace\n",
    "\n",
    "from nrel.mappymatch.readers.tomtom import read_tomtom_nxmap_from_sql\n",
    "from nrel.mappymatch.readers.tomtom_config import TomTomConfig \n",
    "from mappymatch.matchers.lcss.lcss import LCSSMatcher\n",
    "from gradeit.gradeit import gradeit\n",
    "from shapely.geometry import Polygon, Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fdda53-0bc6-4408-a890-419ab5cfb475",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "City variable: choose from \"saltlake\" or \"richmond\", or other agencies with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b6c6b1-900d-4375-bc54-540f8af26357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select city for analysis\n",
    "#city = 'Niagara_Region_Transit'\n",
    "city = 'richmond'#'RTD'#'saltlake'\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "df_shape = pd.read_csv(f'./GTFS_Data/{city}/shapes.txt', sep=',', header=0)\n",
    "df_route = pd.read_csv(f'./GTFS_Data/{city}/routes.txt', sep=',', header=0)\n",
    "df_trips = pd.read_csv(f'./GTFS_Data/{city}/trips.txt', sep=',', header=0)\n",
    "df_stops = pd.read_csv(f'./GTFS_Data/{city}/stops.txt', sep=',', header=0)\n",
    "df_stops_times = pd.read_csv(f'./GTFS_Data/{city}/stop_times.txt', sep=',', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5296645d-c87e-4af6-b3af-5e701e2d9c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of routes\n",
    "df_route.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bdf22a-30e3-40a2-80c4-5079b07783c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show route_type; type 3 is transit buses\n",
    "df_route.route_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41050624-c854-4fce-b6f1-b5770c3dbf4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select shapes for bus routes only\n",
    "\n",
    "\"route_type\" column indicates the type of transportation used on a route. Valid options are:\n",
    "\n",
    "0 - Tram, Streetcar, Light rail. Any light rail or street level system within a metropolitan area.\n",
    "\n",
    "1 - Subway, Metro. Any underground rail system within a metropolitan area.\n",
    "\n",
    "2 - Rail. Used for intercity or long-distance travel.\n",
    "\n",
    "3 - Bus. Used for short- and long-distance bus routes.\n",
    "\n",
    "4 - Ferry. Used for short- and long-distance boat service.\n",
    "\n",
    "5 - Cable tram. Used for street-level rail cars where the cable runs beneath the vehicle (e.g., cable car in San Francisco).\n",
    "\n",
    "6 - Aerial lift, suspended cable car (e.g., gondola lift, aerial tramway). Cable transport where cabins, cars, gondolas or open chairs are suspended by means of one or more cables.\n",
    "\n",
    "7 - Funicular. Any rail system designed for steep inclines.\n",
    "\n",
    "11 - Trolleybus. Electric buses that draw power from overhead wires using poles.\n",
    "\n",
    "12 - Monorail. Railway in which the track consists of a single rail or a beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22c5bb8-4b2e-468e-a3d6-84cae950b30f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Shapes:  (138941, 5)\n",
      "Bus Only Shapes:  (137557, 5)\n"
     ]
    }
   ],
   "source": [
    "# Extract Bus Only Shapes\n",
    "shape_route_key = df_trips[['shape_id','route_id']].drop_duplicates() \n",
    "\n",
    "df_shape_bus = pd.merge(df_shape, shape_route_key, how='left', on='shape_id')\n",
    "df_shape_bus = pd.merge(df_shape_bus, df_route[['route_id','route_type']], how='left', on='route_id')\n",
    "\n",
    "# Select only bus services (route_type = 3)\n",
    "print(\"All Shapes: \", df_shape.shape)\n",
    "df_shape_bus = df_shape_bus[df_shape_bus['route_type']==3]\n",
    "df_shape_bus = df_shape_bus.drop(columns=['route_id', 'route_type'])\n",
    "df_shape = df_shape_bus.copy()\n",
    "print(\"Bus Only Shapes: \", df_shape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703eb4bb-b899-42c6-8d0e-f3e5341b4b29",
   "metadata": {},
   "source": [
    "## GTFS Outputs for R Shiny Dashboard\n",
    "- Unique shapes for each service block\n",
    "- Unique stops for each shape in each service block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16caaf6a-3699-442e-8e93-838dda26bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./R_Shiny_Results'):\n",
    "    os.mkdir('./R_Shiny_Results')\n",
    "if not os.path.exists('./R_Shiny_Results/{}'.format(city)):\n",
    "    os.mkdir('./R_Shiny_Results/{}'.format(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38aec07f-bf6c-48b8-b415-3be2796dbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's store the block shapes and block stops for each day of the week\n",
    "# Seems like some GTFS data do not have calendar data, we treat them as outliars for now\n",
    "\n",
    "try:\n",
    "    df_calendar = pd.read_csv(f'./GTFS_Data/{city}/calendar.txt', sep=',', header=0)\n",
    "except:\n",
    "    print(\"The df_calendar file for {} read in failed !!!\".format(city))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2281a59-70f5-4a04-98f8-eb745e546695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Start and End Date!\n"
     ]
    }
   ],
   "source": [
    "# We will need to rely on df_calendar to understand the service_id for each day of the week.\n",
    "\n",
    "# We assume that only one start_date and one end_date (seem like a lot of transit agencies do not meet this requirement)\n",
    "# Instead we ensure that the min end date is larger than max start date such that all service blocks have overlaps at least\n",
    "\n",
    "### A dictionary to save the list of service_id for each day of the week\n",
    "dict_service_id_list = {}\n",
    "if len(df_calendar.start_date.unique()) == 1 and len(df_calendar.end_date.unique()) == 1:\n",
    "    print(\"Unique Start and End Date!\")\n",
    "    \n",
    "    for day_of_week in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday','saturday', 'sunday']:\n",
    "        if day_of_week in df_calendar.columns:\n",
    "            dict_service_id_list[day_of_week] = df_calendar[df_calendar[day_of_week] == 1].service_id.to_list()\n",
    "        else: ### Deal with the case where column name has an additional space\n",
    "            match_column = [col_tmp for col_tmp in df_calendar.columns if day_of_week in col_tmp][0]\n",
    "            dict_service_id_list[day_of_week] = df_calendar[df_calendar[match_column] == 1].service_id.to_list()\n",
    "\n",
    "elif df_calendar.start_date.max() < df_calendar.end_date.min(): ### Make sure overlap exist for all service block effective dates\n",
    "    print(\"The df_calendar file for {} is abnormal!!!\".format(city),\"but the dates have overlapped region!\")\n",
    "    \n",
    "    for day_of_week in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday','saturday', 'sunday']:\n",
    "        if day_of_week in df_calendar.columns:\n",
    "            dict_service_id_list[day_of_week] = df_calendar[df_calendar[day_of_week] == 1].service_id.to_list()\n",
    "        else: ### Deal with the case where column name has an additional space\n",
    "            match_column = [col_tmp for col_tmp in df_calendar.columns if day_of_week in col_tmp][0]\n",
    "            dict_service_id_list[day_of_week] = df_calendar[df_calendar[match_column] == 1].service_id.to_list()\n",
    "\n",
    "### Remove those special day (one day services)\n",
    "else:\n",
    "    print(\"Warning!!!, The df_calendar file for {} is abnormal!!!\".format(city),\"but the dates have no overlapped region!\")\n",
    "    ### Only consider the largest (normal range)\n",
    "\n",
    "    df_calendar['start_date'] = df_calendar['start_date'].apply(lambda x: str(x)[0:4] + '-' + str(x)[4:6] + '-' + str(x)[6:])\n",
    "    df_calendar['end_date'] = df_calendar['end_date'].apply(lambda x: str(x)[0:4] + '-' + str(x)[4:6] + '-' + str(x)[6:])\n",
    "\n",
    "    df_calendar['start_date'] = pd.to_datetime(df_calendar['start_date'])\n",
    "    df_calendar['end_date'] = pd.to_datetime(df_calendar['end_date'])\n",
    "\n",
    "    df_calendar['service_duration'] = df_calendar['end_date']  - df_calendar['start_date'] \n",
    "    df_calendar = df_calendar[df_calendar.service_duration == df_calendar.service_duration.max()]\n",
    "\n",
    "    for day_of_week in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday','saturday', 'sunday']:\n",
    "        if day_of_week in df_calendar.columns:\n",
    "            dict_service_id_list[day_of_week] = df_calendar[df_calendar[day_of_week] == 1].service_id.to_list()\n",
    "        else: ### Deal with the case where column name has an additional space\n",
    "            match_column = [col_tmp for col_tmp in df_calendar.columns if day_of_week in col_tmp][0]\n",
    "            dict_service_id_list[day_of_week] = df_calendar[df_calendar[match_column] == 1].service_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0fbcca-7a59-4337-9221-9cf1afac56c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monday': [1],\n",
       " 'tuesday': [1],\n",
       " 'wednesday': [1],\n",
       " 'thursday': [1],\n",
       " 'friday': [1],\n",
       " 'saturday': [3],\n",
       " 'sunday': [2]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_service_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69e8fea-9311-4d74-88b5-5f45d7e3d126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All routes block shape:  (1265, 6)\n",
      "Bus only reoute block shape:  (1265, 6)\n"
     ]
    }
   ],
   "source": [
    "## Merge trip shape with shape dataframe to have the 'shape_pt_lat', 'shape_pt_lon'\n",
    "\n",
    "df_trips_block = df_trips[['route_id','block_id', 'shape_id','service_id']] #'trip_headsign','direction_id',\n",
    "df_trips_block = df_trips_block.drop_duplicates(ignore_index=True)\n",
    "\n",
    "df_trips_block = pd.merge(df_trips_block, df_route[['route_id','route_type','route_short_name']], how='left', on='route_id')\n",
    "\n",
    "# select only bus services (route_type = 3)\n",
    "print(\"All routes block shape: \", df_trips_block.shape)\n",
    "df_trips_block_bus = df_trips_block[df_trips_block['route_type']==3]\n",
    "print(\"Bus only reoute block shape: \", df_trips_block_bus.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa03e03b-bced-4cb1-ba5e-b064d6081841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Blocks: 349\n",
      "Transit Bus Blocks: 349\n"
     ]
    }
   ],
   "source": [
    "### Further merge with shape to get the gps points\n",
    "\n",
    "block_shapes = pd.merge(df_trips_block_bus, df_shape, how='left', on='shape_id')\n",
    "select_cols = ['route_id', 'block_id', 'shape_id','route_short_name',  # 'trip_headsign', 'direction_id', \n",
    "       'shape_pt_lat', 'shape_pt_lon', 'shape_pt_sequence','service_id']\n",
    "\n",
    "print('All Blocks:',len(block_shapes.block_id.unique()))\n",
    "block_shapes = block_shapes[select_cols].dropna() ##Drop nan to filter out blocks without bus shapes (i.e., rail etc.)\n",
    "print('Transit Bus Blocks:',len(block_shapes.block_id.unique()))\n",
    "block_shapes.to_csv('./R_Shiny_Results/{}/block_shapes_{}.csv'.format(city, city), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba720329-fba9-4ce6-89b4-7f33fd44aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Blocks: 349\n",
      "Transit Bus Blocks: 349\n"
     ]
    }
   ],
   "source": [
    "###  Now extract stops\n",
    "df_stops_merged = pd.merge(df_stops_times, df_stops, how='left', on='stop_id')\n",
    "\n",
    "df_stops_merged = df_stops_merged[['trip_id','stop_id', 'stop_sequence',\n",
    "                                  'stop_name', 'stop_desc', 'stop_lat','stop_lon']]\n",
    "df_block_stops = pd.merge(df_trips, df_stops_merged, how='left', on='trip_id')\n",
    "# remove trip_id, just want shapes and stops for each block\n",
    "df_block_stops = df_block_stops[['route_id','direction_id', 'block_id', 'shape_id', \n",
    "                                'stop_id', 'stop_sequence', 'stop_name', 'stop_desc',\n",
    "                                 'stop_lat', 'stop_lon']]\n",
    "\n",
    "### Merge route to get route name\n",
    "df_block_stops  = df_block_stops.merge(df_route[['route_id','route_short_name']], how='left', on='route_id')\n",
    "\n",
    "print('All Blocks:',len(df_block_stops.block_id.unique()))\n",
    "df_block_stops = df_block_stops[df_block_stops.block_id.isin(block_shapes.block_id.unique())] ## Only get stop for transit buses\n",
    "\n",
    "print('Transit Bus Blocks:',len(df_block_stops.block_id.unique()))\n",
    "df_block_stops = df_block_stops.drop_duplicates(ignore_index=True)\n",
    "\n",
    "df_block_stops.to_csv('./R_Shiny_Results/{}/block_stops_{}.csv'.format(city, city), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df188a72-6a4a-4d26-938a-79bb2bdbcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For each block_id merge the route short name\n",
    "block_shapes_group = block_shapes[['block_id','route_short_name']].groupby('block_id').agg(lambda x: 'Route_' + '_Route_'.join(x.unique()))\n",
    "\n",
    "block_shapes_group = block_shapes_group.reset_index()\n",
    "\n",
    "block_shapes_group['block_id_new'] =block_shapes_group['route_short_name'] + '_' +  block_shapes_group['block_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96913c4c-e03e-46d6-856c-e6c636d164a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110  Blocks for  monday\n",
      "110  Blocks for  tuesday\n",
      "110  Blocks for  wednesday\n",
      "110  Blocks for  thursday\n",
      "110  Blocks for  friday\n",
      "81  Blocks for  saturday\n",
      "63  Blocks for  sunday\n"
     ]
    }
   ],
   "source": [
    "### Extract the blocks and shapes for each day of the week\n",
    "\n",
    "for day_of_week in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday','saturday', 'sunday']:\n",
    "    service_block_list = dict_service_id_list[day_of_week]\n",
    "    print(len(block_shapes[block_shapes.service_id.isin(service_block_list)].block_id.unique()), \" Blocks for \",day_of_week)\n",
    "    block_shapes_tmp_day = block_shapes[block_shapes.service_id.isin(service_block_list)]\n",
    "    df_block_stops_tmp_day = df_block_stops[df_block_stops.block_id.isin(block_shapes_tmp_day.block_id.unique())]\n",
    "\n",
    "\n",
    "    block_shapes_tmp_day = block_shapes_tmp_day.merge(block_shapes_group[['block_id','block_id_new']],how = 'left',on='block_id')\n",
    "\n",
    "    block_shapes_tmp_day['block_id'] = block_shapes_tmp_day['block_id_new']\n",
    "    block_shapes_tmp_day.to_csv('./R_Shiny_Results/{}/block_shapes_{}_{}.csv'.format(city, city, day_of_week), index=False)\n",
    "\n",
    "    df_block_stops_tmp_day = df_block_stops_tmp_day.merge(block_shapes_group[['block_id','block_id_new']],how = 'left',on='block_id')\n",
    "    df_block_stops_tmp_day['block_id'] = df_block_stops_tmp_day['block_id_new']\n",
    "    df_block_stops_tmp_day.to_csv('./R_Shiny_Results/{}/block_stops_{}_{}.csv'.format(city, city, day_of_week), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b30ec19a-653d-4247-b638-f238a746d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might further compare those number of service blocks with the fleet size\n",
    "# to see whether it is feasible to serve each block with one vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4986257-b4a3-435e-aae3-d96452cf101d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
