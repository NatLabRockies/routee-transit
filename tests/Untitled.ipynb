{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0545ea9b-42c7-4570-bd08-cef4f69b2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geopy.distance import great_circle\n",
    "from gtfsblocks import Feed, filter_blocks_by_route\n",
    "from mappymatch.constructs.geofence import Geofence\n",
    "from mappymatch.constructs.trace import Trace\n",
    "from mappymatch.maps.nx.nx_map import NetworkType, NxMap\n",
    "from mappymatch.matchers.lcss.lcss import LCSSMatcher\n",
    "\n",
    "from nrel.routee.transit.prediction.grade.add_grade import run_gradeit_parallel\n",
    "from nrel.routee.transit.prediction.grade.tile_resolution import TileResolution\n",
    "from nrel.routee.transit.prediction.create_depot_deadhead_trips import create_depot_deadhead_trips\n",
    "from nrel.routee.transit.prediction.create_depot_deadhead_stops import create_depot_deadhead_stops\n",
    "from nrel.routee.transit.prediction.create_betweenTrip_deadhead_trips import create_betweenTrip_deadhead_trips\n",
    "from nrel.routee.transit.prediction.create_betweenTrip_deadhead_stops import create_betweenTrip_deadhead_stops\n",
    "from nrel.routee.transit.prediction.add_depot_to_blocks import add_depot_to_blocks  \n",
    "from nrel.routee.transit.prediction.generate_deadhead_traces import add_deadhead_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66d190f8-79f6-4da5-aeac-ef2291f8f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = {\n",
    "        \"stop_times\": [\n",
    "            \"arrival_time\",\n",
    "            \"departure_time\",\n",
    "            \"shape_dist_traveled\",\n",
    "            \"stop_id\",\n",
    "        ],\n",
    "        \"shapes\": [\"shape_dist_traveled\"],\n",
    "    }\n",
    "feed = Feed.from_dir('/Users/yhe/github_repo/routee-transit/sample-inputs/saltlake/gtfs', columns=req_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cecc11a-247f-4143-9353-6415a8f317c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips = feed.trips\n",
    "trips_df = all_trips[all_trips['route_id'] == '27614']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3118c59a-0d9d-4aac-bc52-e947609a3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_incl=\"2023/08/02\"\n",
    "routes_incl=[\"205\"]\n",
    "\n",
    "if date_incl is not None:\n",
    "    trips_df = feed.get_trips_from_date(date_incl)\n",
    "    if len(trips_df) == 0:\n",
    "        raise ValueError(f\"Feed does not contain any trips on {date_incl}\")\n",
    "else:\n",
    "    trips_df = feed.get_trips_from_sids(feed.trips.service_id.unique().tolist())\n",
    "\n",
    "if routes_incl is not None:\n",
    "    trips_df = filter_blocks_by_route(\n",
    "        trips=trips_df,\n",
    "        routes=routes_incl,\n",
    "        route_column=\"route_short_name\",\n",
    "        route_method=\"exclusive\",\n",
    "    )\n",
    "\n",
    "    if len(trips_df) == 0:\n",
    "        raise ValueError(\n",
    "            \"There are no active trips on your selected routes and date.\"\n",
    "        )\n",
    "\n",
    "shapes_incl = trips_df.shape_id.unique()\n",
    "shapes_df = feed.shapes[feed.shapes.shape_id.isin(shapes_incl)]\n",
    "# logger.info(\n",
    "#     f\"Restricted feed to {len(trips_df)} trips and {len(shapes_incl)} shapes\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee93ccb8-d213-4c4e-a211-056f8e1ffb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a474f22b-1d1d-419e-bbe7-ae9b064904fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>service_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_desc</th>\n",
       "      <th>agency_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>5170968</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>5170969</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>5170970</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6069</th>\n",
       "      <td>5170972</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6070</th>\n",
       "      <td>5170973</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>5170974</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>5170975</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>5170976</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>5170977</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>5170979</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>5170980</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>5170981</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6079</th>\n",
       "      <td>5170982</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>5170983</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>5170984</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>5170986</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6084</th>\n",
       "      <td>5170987</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>5170988</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>5170989</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>5170990</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>5170991</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>5170992</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>5170993</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6091</th>\n",
       "      <td>5170994</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>5170995</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>5170996</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>5170997</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>5170998</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226466</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>5171000</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>5171001</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>5171002</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>5171003</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>5171004</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>5171006</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6104</th>\n",
       "      <td>5171007</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>5171008</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>5171009</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>5171010</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>5171011</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>5171013</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>5171014</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>5171015</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>5171016</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>5171017</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>5171018</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>5171020</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>5171021</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>5171022</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>5171023</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>5171024</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>5171025</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155704</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>5171026</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155700</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>5171027</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155705</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>5171028</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155701</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>5171029</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155702</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>5171030</td>\n",
       "      <td>27614</td>\n",
       "      <td>4</td>\n",
       "      <td>1155703</td>\n",
       "      <td>226467</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trip_id route_id service_id block_id shape_id route_short_name  \\\n",
       "6065  5170968    27614          4  1155702   226466              205   \n",
       "6066  5170969    27614          4  1155703   226466              205   \n",
       "6067  5170970    27614          4  1155704   226466              205   \n",
       "6069  5170972    27614          4  1155700   226466              205   \n",
       "6070  5170973    27614          4  1155705   226466              205   \n",
       "6071  5170974    27614          4  1155701   226466              205   \n",
       "6072  5170975    27614          4  1155702   226466              205   \n",
       "6073  5170976    27614          4  1155703   226466              205   \n",
       "6074  5170977    27614          4  1155704   226466              205   \n",
       "6076  5170979    27614          4  1155700   226466              205   \n",
       "6077  5170980    27614          4  1155705   226466              205   \n",
       "6078  5170981    27614          4  1155701   226466              205   \n",
       "6079  5170982    27614          4  1155702   226466              205   \n",
       "6080  5170983    27614          4  1155703   226466              205   \n",
       "6081  5170984    27614          4  1155704   226466              205   \n",
       "6083  5170986    27614          4  1155700   226466              205   \n",
       "6084  5170987    27614          4  1155705   226466              205   \n",
       "6085  5170988    27614          4  1155701   226466              205   \n",
       "6086  5170989    27614          4  1155702   226466              205   \n",
       "6087  5170990    27614          4  1155703   226466              205   \n",
       "6088  5170991    27614          4  1155704   226466              205   \n",
       "6089  5170992    27614          4  1155700   226466              205   \n",
       "6090  5170993    27614          4  1155705   226466              205   \n",
       "6091  5170994    27614          4  1155701   226466              205   \n",
       "6092  5170995    27614          4  1155702   226466              205   \n",
       "6093  5170996    27614          4  1155703   226466              205   \n",
       "6094  5170997    27614          4  1155704   226466              205   \n",
       "6095  5170998    27614          4  1155700   226466              205   \n",
       "6097  5171000    27614          4  1155700   226467              205   \n",
       "6098  5171001    27614          4  1155701   226467              205   \n",
       "6099  5171002    27614          4  1155702   226467              205   \n",
       "6100  5171003    27614          4  1155703   226467              205   \n",
       "6101  5171004    27614          4  1155704   226467              205   \n",
       "6103  5171006    27614          4  1155700   226467              205   \n",
       "6104  5171007    27614          4  1155705   226467              205   \n",
       "6105  5171008    27614          4  1155701   226467              205   \n",
       "6106  5171009    27614          4  1155702   226467              205   \n",
       "6107  5171010    27614          4  1155703   226467              205   \n",
       "6108  5171011    27614          4  1155704   226467              205   \n",
       "6110  5171013    27614          4  1155700   226467              205   \n",
       "6111  5171014    27614          4  1155705   226467              205   \n",
       "6112  5171015    27614          4  1155701   226467              205   \n",
       "6113  5171016    27614          4  1155702   226467              205   \n",
       "6114  5171017    27614          4  1155703   226467              205   \n",
       "6115  5171018    27614          4  1155704   226467              205   \n",
       "6117  5171020    27614          4  1155700   226467              205   \n",
       "6118  5171021    27614          4  1155705   226467              205   \n",
       "6119  5171022    27614          4  1155701   226467              205   \n",
       "6120  5171023    27614          4  1155702   226467              205   \n",
       "6121  5171024    27614          4  1155703   226467              205   \n",
       "6122  5171025    27614          4  1155704   226467              205   \n",
       "6123  5171026    27614          4  1155700   226467              205   \n",
       "6124  5171027    27614          4  1155705   226467              205   \n",
       "6125  5171028    27614          4  1155701   226467              205   \n",
       "6126  5171029    27614          4  1155702   226467              205   \n",
       "6127  5171030    27614          4  1155703   226467              205   \n",
       "\n",
       "      route_type route_desc agency_id  \n",
       "6065           3        NaN       NaN  \n",
       "6066           3        NaN       NaN  \n",
       "6067           3        NaN       NaN  \n",
       "6069           3        NaN       NaN  \n",
       "6070           3        NaN       NaN  \n",
       "6071           3        NaN       NaN  \n",
       "6072           3        NaN       NaN  \n",
       "6073           3        NaN       NaN  \n",
       "6074           3        NaN       NaN  \n",
       "6076           3        NaN       NaN  \n",
       "6077           3        NaN       NaN  \n",
       "6078           3        NaN       NaN  \n",
       "6079           3        NaN       NaN  \n",
       "6080           3        NaN       NaN  \n",
       "6081           3        NaN       NaN  \n",
       "6083           3        NaN       NaN  \n",
       "6084           3        NaN       NaN  \n",
       "6085           3        NaN       NaN  \n",
       "6086           3        NaN       NaN  \n",
       "6087           3        NaN       NaN  \n",
       "6088           3        NaN       NaN  \n",
       "6089           3        NaN       NaN  \n",
       "6090           3        NaN       NaN  \n",
       "6091           3        NaN       NaN  \n",
       "6092           3        NaN       NaN  \n",
       "6093           3        NaN       NaN  \n",
       "6094           3        NaN       NaN  \n",
       "6095           3        NaN       NaN  \n",
       "6097           3        NaN       NaN  \n",
       "6098           3        NaN       NaN  \n",
       "6099           3        NaN       NaN  \n",
       "6100           3        NaN       NaN  \n",
       "6101           3        NaN       NaN  \n",
       "6103           3        NaN       NaN  \n",
       "6104           3        NaN       NaN  \n",
       "6105           3        NaN       NaN  \n",
       "6106           3        NaN       NaN  \n",
       "6107           3        NaN       NaN  \n",
       "6108           3        NaN       NaN  \n",
       "6110           3        NaN       NaN  \n",
       "6111           3        NaN       NaN  \n",
       "6112           3        NaN       NaN  \n",
       "6113           3        NaN       NaN  \n",
       "6114           3        NaN       NaN  \n",
       "6115           3        NaN       NaN  \n",
       "6117           3        NaN       NaN  \n",
       "6118           3        NaN       NaN  \n",
       "6119           3        NaN       NaN  \n",
       "6120           3        NaN       NaN  \n",
       "6121           3        NaN       NaN  \n",
       "6122           3        NaN       NaN  \n",
       "6123           3        NaN       NaN  \n",
       "6124           3        NaN       NaN  \n",
       "6125           3        NaN       NaN  \n",
       "6126           3        NaN       NaN  \n",
       "6127           3        NaN       NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7574595-99f7-4d5b-ab95-f3cd42c71373",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadhead_trips_df = create_depot_deadhead_trips(trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df7ed7f4-2eee-4035-ad30-cc37403fca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "depot_directory = '/Users/yhe/github_repo/routee-transit/FTA_Depot/Transit_Depot.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac3f598-de7f-47af-89d2-15f4063aaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stops_gdf, last_stops_gdf = add_depot_to_blocks(trips_df, feed, path_to_depots=depot_directory)\n",
    "deadhead_stop_times_df, deadhead_stops_df = create_depot_deadhead_stops(first_stops_gdf, last_stops_gdf, deadhead_trips_df)\n",
    "# Generate deadhead trip shapes for trips from depot to first stop\n",
    "all_points = pd.concat([first_stops_gdf['geometry_origin'], first_stops_gdf['geometry_destination']])\n",
    "lons = all_points.apply(lambda p: p.x)\n",
    "lats = all_points.apply(lambda p: p.y)\n",
    "min_lon, max_lon = lons.min(), lons.max() # Bounding box\n",
    "min_lat, max_lat = lats.min(), lats.max() # Bounding box\n",
    "buffer_deg_lat = 0.018     # Roughly 2 km buffer in degrees\n",
    "buffer_deg_lon = 0.022     # Roughly 2 km buffer in degrees\n",
    "miny = min_lat - buffer_deg_lat\n",
    "maxy = max_lat + buffer_deg_lat\n",
    "minx = min_lon - buffer_deg_lon\n",
    "maxx = max_lon + buffer_deg_lon\n",
    "from_depot_deadhead_shapes_df = add_deadhead_trips(\n",
    "    df = first_stops_gdf,\n",
    "    n_processes = 1,\n",
    "    bbox = [minx, miny, maxx, maxy]\n",
    "    )\n",
    "from_depot_deadhead_shapes_df['shape_id'] = from_depot_deadhead_shapes_df['shape_id'].apply(lambda x: 'from_depot_' + x)\n",
    "# Generate deadhead trip shapes for trips from last stop to depot\n",
    "all_points = pd.concat([last_stops_gdf['geometry_origin'], last_stops_gdf['geometry_destination']])\n",
    "lons = all_points.apply(lambda p: p.x)\n",
    "lats = all_points.apply(lambda p: p.y)\n",
    "min_lon, max_lon = lons.min(), lons.max() # Bounding box\n",
    "min_lat, max_lat = lats.min(), lats.max() # Bounding box\n",
    "buffer_deg_lat = 0.018     # Roughly 2 km buffer in degrees\n",
    "buffer_deg_lon = 0.022     # Roughly 2 km buffer in degrees         \n",
    "miny = min_lat - buffer_deg_lat\n",
    "maxy = max_lat + buffer_deg_lat\n",
    "minx = min_lon - buffer_deg_lon\n",
    "maxx = max_lon + buffer_deg_lon\n",
    "to_depot_deadhead_shapes_df = add_deadhead_trips(\n",
    "    df = last_stops_gdf,\n",
    "    n_processes = 1,\n",
    "    bbox = [minx, miny, maxx, maxy]\n",
    "    )\n",
    "to_depot_deadhead_shapes_df['shape_id'] = to_depot_deadhead_shapes_df['shape_id'].apply(lambda x: 'to_depot_' + x)\n",
    "# Combine all deadhead shapes\n",
    "deadhead_shapes_df = pd.concat([from_depot_deadhead_shapes_df, to_depot_deadhead_shapes_df], ignore_index=True)\n",
    "\n",
    "# Update trips_df, shapes_df, and feed\n",
    "# Before updating, update deadhead_trips_df as some blocks may have the same first and last stop therefore won't shown in deadhead_shapes_df\n",
    "deadhead_trips_df = deadhead_trips_df[deadhead_trips_df['shape_id'].isin(deadhead_shapes_df['shape_id'].unique())]\n",
    "# Update trips_df, shapes_df, and feed\n",
    "trips_df_1 = pd.concat([trips_df, deadhead_trips_df], ignore_index=True)\n",
    "shapes_df = pd.concat([shapes_df, deadhead_shapes_df], ignore_index=True)\n",
    "feed.trips = pd.concat([feed.trips, deadhead_trips_df], ignore_index=True)\n",
    "feed.shapes = pd.concat([feed.shapes, deadhead_shapes_df], ignore_index=True)\n",
    "feed.stop_times = pd.concat([feed.stop_times, deadhead_stop_times_df], ignore_index=True)\n",
    "feed.stops = pd.concat([feed.stops, deadhead_stops_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbd48349-0d33-47d5-b521-723779934de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenTrip_deadhead_trips_df = create_betweenTrip_deadhead_trips(trips_df,stop_times_df)\n",
    "# Create between trip deadhead stop_times and stops\n",
    "betweenTrip_deadhead_stop_times_df, betweenTrip_deadhead_stops_df, betweenTrip_ODs = create_betweenTrip_deadhead_stops(feed, betweenTrip_deadhead_trips_df)\n",
    "# Generate deadhead trip shapes for trips from depot to first stop\n",
    "all_points = pd.concat([betweenTrip_ODs['geometry_origin'], betweenTrip_ODs['geometry_destination']])\n",
    "lons = all_points.apply(lambda p: p.x)\n",
    "lats = all_points.apply(lambda p: p.y)\n",
    "min_lon, max_lon = lons.min(), lons.max() # Bounding box\n",
    "min_lat, max_lat = lats.min(), lats.max() # Bounding box\n",
    "buffer_deg_lat = 0.018     # Roughly 2 km buffer in degrees\n",
    "buffer_deg_lon = 0.022     # Roughly 2 km buffer in degrees\n",
    "miny = min_lat - buffer_deg_lat\n",
    "maxy = max_lat + buffer_deg_lat\n",
    "minx = min_lon - buffer_deg_lon\n",
    "maxx = max_lon + buffer_deg_lon\n",
    "# Remove ODs with same origin and destination\n",
    "betweenTrip_ODs = betweenTrip_ODs[betweenTrip_ODs.geometry_origin != betweenTrip_ODs.geometry_destination]\n",
    "betweenTrip_deadhead_shapes_df = add_deadhead_trips(\n",
    "    df = betweenTrip_ODs,\n",
    "    n_processes = 1,\n",
    "    bbox = [minx, miny, maxx, maxy]\n",
    "    )\n",
    "\n",
    "# Update trips_df, shapes_df, and feed\n",
    "# Before updating, update deadhead_trips_df as some blocks may have the same first and last stop therefore won't shown in deadhead_shapes_df\n",
    "betweenTrip_deadhead_trips_df = betweenTrip_deadhead_trips_df[betweenTrip_deadhead_trips_df['shape_id'].isin(betweenTrip_deadhead_shapes_df['shape_id'].unique())]\n",
    "# Update trips_df, shapes_df, and feed\n",
    "trips_df_2 = pd.concat([trips_df_1, betweenTrip_deadhead_trips_df], ignore_index=True)\n",
    "shapes_df = pd.concat([shapes_df, betweenTrip_deadhead_shapes_df], ignore_index=True)\n",
    "feed.trips = pd.concat([feed.trips, betweenTrip_deadhead_trips_df], ignore_index=True)\n",
    "feed.shapes = pd.concat([feed.shapes, betweenTrip_deadhead_shapes_df], ignore_index=True)\n",
    "feed.stop_times = pd.concat([feed.stop_times, betweenTrip_deadhead_stop_times_df], ignore_index=True)\n",
    "feed.stops = pd.concat([feed.stops, betweenTrip_deadhead_stops_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6c0c133-b566-47fd-a87c-0f7e49b6e085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = feed.shapes\n",
    "len(test['shape_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ffd5dba9-1b56-4162-b17d-0517236017b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shapes_df['shape_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d16a1418-507d-4f85-a694-941a688f3d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['226466', '226467', 'from_depot_1155700', 'from_depot_1155701',\n",
       "       'from_depot_1155702', 'from_depot_1155703', 'from_depot_1155704',\n",
       "       'from_depot_1155705', 'to_depot_1155700', 'to_depot_1155701',\n",
       "       'to_depot_1155702', 'to_depot_1155703', 'to_depot_1155704',\n",
       "       'to_depot_1155705', '5171000_to_5170972', '5171006_to_5170979',\n",
       "       '5171013_to_5170986', '5171020_to_5170992', '5171026_to_5170998',\n",
       "       '5171001_to_5170974', '5171008_to_5170981', '5171015_to_5170988',\n",
       "       '5171022_to_5170994', '5171002_to_5170975', '5171009_to_5170982',\n",
       "       '5171016_to_5170989', '5171023_to_5170995', '5171003_to_5170976',\n",
       "       '5171010_to_5170983', '5171017_to_5170990', '5171024_to_5170996',\n",
       "       '5171004_to_5170977', '5171011_to_5170984', '5171018_to_5170991',\n",
       "       '5171025_to_5170997', '5171007_to_5170980', '5171014_to_5170987',\n",
       "       '5171021_to_5170993'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes_df['shape_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dca033e-0d17-464c-8f66-2c4392db7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_shape(shape_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Upsample a GTFS shape DataFrame to generate a roughly 1 Hz GPS trace.\n",
    "\n",
    "    Interpolates latitude, longitude, and distance traveled, assuming a constant speed.\n",
    "    The function performs the following steps:\n",
    "\n",
    "    * Calculates the distance between consecutive shape points using great-circle distance\n",
    "    * Computes the cumulative distance traveled along the shape\n",
    "    * Assigns timestamps based on constant speed (30 km/h)\n",
    "    * Resamples and interpolates the shape to 1-second intervals\n",
    "    * Returns DataFrame with interpolated coordinates, timestamps, and distances\n",
    "\n",
    "    Args:\n",
    "        shape_df: DataFrame containing GTFS shape points with columns\n",
    "            'shape_pt_lat', 'shape_pt_lon', and 'shape_id'.\n",
    "\n",
    "    Returns:\n",
    "        Upsampled DataFrame with columns 'shape_pt_lat', 'shape_pt_lon',\n",
    "        'shape_dist_traveled', 'timestamp', and 'shape_id', sampled at 1 Hz.\n",
    "    \"\"\"\n",
    "\n",
    "    # Shift latitude and longitude to get previous point\n",
    "    shape_df[\"prev_latitude\"] = shape_df[\"shape_pt_lat\"].shift()\n",
    "    shape_df[\"prev_longitude\"] = shape_df[\"shape_pt_lon\"].shift()\n",
    "\n",
    "    # Calculate the distance between consecutive points using great_circle\n",
    "    # TODO: move away from apply() for speed\n",
    "    shape_df[\"distance_km\"] = shape_df.apply(\n",
    "        lambda row: great_circle(\n",
    "            (row[\"prev_latitude\"], row[\"prev_longitude\"]),  # Previous point\n",
    "            (row[\"shape_pt_lat\"], row[\"shape_pt_lon\"]),  # Current point\n",
    "        ).kilometers\n",
    "        if pd.notnull(row[\"prev_latitude\"])\n",
    "        else 0,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Calculate total distance\n",
    "    total_distance_km = shape_df[\"distance_km\"].sum()\n",
    "\n",
    "    # Use calculated total distance instead of shape_dist_traveled\n",
    "    shape_df[\"shape_dist_traveled\"] = shape_df[\"distance_km\"].cumsum()\n",
    "\n",
    "    # Speed is assumed to be 30 km/h, which is about 10 (8.33) m per second/node\n",
    "    shape_df[\"segment_duration_delta\"] = (\n",
    "        shape_df[\"shape_dist_traveled\"]\n",
    "        / shape_df[\"shape_dist_traveled\"].max()\n",
    "        * datetime.timedelta(seconds=round(total_distance_km / 30 * 3600))\n",
    "    )\n",
    "    shape_df[\"segment_duration_delta\"] = shape_df[\"segment_duration_delta\"].apply(\n",
    "        lambda x: datetime.timedelta(seconds=round(x.total_seconds()))\n",
    "    )\n",
    "    # Define an arbitrary date to convert from timedelta to datetime\n",
    "    date_tmp = datetime.datetime(2023, 9, 3)\n",
    "    shape_df[\"timestamp\"] = (\n",
    "        datetime.timedelta(seconds=0) + shape_df[\"segment_duration_delta\"] + date_tmp\n",
    "    )\n",
    "\n",
    "    # Upsample to 1s\n",
    "    shape_id_tmp = shape_df.shape_id.iloc[0]\n",
    "    shape_df = (\n",
    "        shape_df[[\"shape_pt_lat\", \"shape_pt_lon\", \"timestamp\", \"shape_dist_traveled\"]]\n",
    "        .drop_duplicates(subset=[\"timestamp\"])\n",
    "        .set_index(\"timestamp\")\n",
    "        .resample(\"1s\")\n",
    "        .interpolate(method=\"linear\")\n",
    "    )\n",
    "\n",
    "    # Now we have the 1 Hz gps trace for each trip with timestamp\n",
    "    shape_df = shape_df.reset_index(drop=True)\n",
    "    shape_df[\"shape_id\"] = shape_id_tmp\n",
    "\n",
    "    return shape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9cb6041-4739-479f-be5b-2017668186c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape_list = [group for _, group in shapes_df.groupby(\"shape_id\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46bcdaf1-bfe5-4c7e-ab31-2f7414d2cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_shapes_list = []\n",
    "for i in range(len(df_shape_list)):\n",
    "    shape_df = df_shape_list[i]\n",
    "    upsampled_shapes = upsample_shape(shape_df)\n",
    "    upsampled_shapes_list.append(upsampled_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a45e04ba-69de-4b18-9770-b8236d2bab58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upsampled_shapes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df62578c-decf-4475-9818-a1321c69b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_shape_to_osm(upsampled_shape_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Match a given GTFS shape DataFrame to the OpenStreetMap (OSM) road network.\n",
    "\n",
    "    This function uses mappymatch to add OSM network information to the shape trace.\n",
    "    The trace should be upsampled beforehand to approximately 1 Hz/8 m for the most\n",
    "    accurate expected mapping performance. The function creates a Trace from the input\n",
    "    DataFrame, constructs a geofence around the trace, extracts the OSM road network\n",
    "    within the geofence, and applies the mappymatch LCSS matcher to align the trace to\n",
    "    the network. The output DataFrame retains the full shape while adding network\n",
    "    information to each row.\n",
    "\n",
    "    Args:\n",
    "        upsampled_shape_df (pd.DataFrame): DataFrame containing the shape points with\n",
    "            latitude and longitude columns (\"shape_pt_lat\" and \"shape_pt_lon\").\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame combining the original upsampled shape points with\n",
    "            their corresponding OSM network matches.\n",
    "    \"\"\"\n",
    "    # Create mappymatch trace\n",
    "    trace = Trace.from_dataframe(\n",
    "        upsampled_shape_df, lat_column=\"shape_pt_lat\", lon_column=\"shape_pt_lon\"\n",
    "    )\n",
    "    # Create geofence and use it to pull network\n",
    "    geofence = Geofence.from_trace(trace, padding=1e3)\n",
    "    nxmap = NxMap.from_geofence(geofence, network_type=NetworkType.DRIVE)\n",
    "    # Run map matching algorithm\n",
    "    matcher = LCSSMatcher(nxmap)\n",
    "    matches = matcher.match_trace(trace).matches_to_dataframe()\n",
    "    # Combine shape with network details\n",
    "    df_result = pd.concat([upsampled_shape_df, matches], axis=1)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "864345dd-d1d0-4341-b2af-c47820d3697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/mappymatch/matchers/match_result.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(np.nan)\n"
     ]
    }
   ],
   "source": [
    "matched_shapes_list = []\n",
    "for i in range(len(upsampled_shapes_list)):\n",
    "    shape_df = upsampled_shapes_list[i]\n",
    "    matched_shapes = match_shape_to_osm(shape_df)\n",
    "    matched_shapes_list.append(matched_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5b108bf-919d-4a74-8404-7c8a24b7b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_shapes_df = pd.concat(matched_shapes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99f241c4-0712-4ea2-b37a-552884220e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched_shapes_df['shape_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3974321-53fa-4898-93da-962f4f3decfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['226466', '226467', '5171000_to_5170972', '5171001_to_5170974',\n",
       "       '5171002_to_5170975', '5171003_to_5170976', '5171004_to_5170977',\n",
       "       '5171006_to_5170979', '5171007_to_5170980', '5171008_to_5170981',\n",
       "       '5171009_to_5170982', '5171010_to_5170983', '5171011_to_5170984',\n",
       "       '5171013_to_5170986', '5171014_to_5170987', '5171015_to_5170988',\n",
       "       '5171016_to_5170989', '5171017_to_5170990', '5171018_to_5170991',\n",
       "       '5171020_to_5170992', '5171021_to_5170993', '5171022_to_5170994',\n",
       "       '5171023_to_5170995', '5171024_to_5170996', '5171025_to_5170997',\n",
       "       '5171026_to_5170998', 'from_depot_1155700', 'from_depot_1155701',\n",
       "       'from_depot_1155702', 'from_depot_1155703', 'from_depot_1155704',\n",
       "       'from_depot_1155705', 'to_depot_1155700', 'to_depot_1155701',\n",
       "       'to_depot_1155702', 'to_depot_1155703', 'to_depot_1155704',\n",
       "       'to_depot_1155705'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_shapes_df['shape_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "563ba14e-3a4c-493b-93fd-3d55a5e0420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_trip_traces(\n",
    "    trips_df: pd.DataFrame,\n",
    "    matched_shapes_df: pd.DataFrame,\n",
    "    feed: Feed,\n",
    "    add_stop_flag: bool = False,\n",
    "    n_processes: int | None = mp.cpu_count(),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Extend trip shapes with stop details and estimated timestamps from GTFS.\n",
    "\n",
    "    This function processes GTFS trip and shape data to:\n",
    "\n",
    "    * Summarize stop times for each trip (first/last stop and times)\n",
    "    * Merge stop time summaries into the trips DataFrame\n",
    "    * Attach stop coordinates to stop times\n",
    "    * Merge trip and shape data to create ordered trip traces\n",
    "    * Optionally, attach stop indicators to shape trace points\n",
    "    * Estimate timestamps for each trace point based on scheduled trip duration and distance\n",
    "\n",
    "    Args:\n",
    "        trips_df: DataFrame containing trip information, including\n",
    "            'trip_id' and 'shape_id'.\n",
    "        matched_shapes_df: DataFrame with shape points matched to trips,\n",
    "            including 'shape_id' and 'shape_dist_traveled'.\n",
    "        feed: GTFS feed object containing 'stop_times' and 'stops'\n",
    "            DataFrames.\n",
    "        add_stop_flag: If True, attaches stop indicators to shape trace\n",
    "            points. Defaults to False.\n",
    "        n_processes: Number of processes to run in parallel using\n",
    "            multiprocessing. Defaults to mp.cpu_count().\n",
    "\n",
    "    Returns:\n",
    "        A list of DataFrames, one per trip, with extended trace information\n",
    "        including estimated timestamps.\n",
    "    \"\"\"\n",
    "    # Start by summarizing stop times: get first and last stop, plus start/end times\n",
    "    stop_times_by_trip = (\n",
    "        feed.stop_times.groupby(\"trip_id\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"arrival_time\": \"first\",\n",
    "                \"departure_time\": \"last\",\n",
    "                \"stop_id\": [\"first\", \"last\"],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    stop_times_by_trip.columns = [\n",
    "        \"trip_id\",\n",
    "        \"o_time\",\n",
    "        \"d_time\",\n",
    "        \"o_stop_id\",\n",
    "        \"d_stop_id\",\n",
    "    ]\n",
    "\n",
    "    # Add start/end times and stops to trips DF\n",
    "    # TODO: consider doing this with gtfsblocks add_trip_data()\n",
    "    trips_df = pd.merge(trips_df, stop_times_by_trip, how=\"left\", on=\"trip_id\")\n",
    "    trips_df[\"o_time\"] = pd.to_timedelta(trips_df[\"o_time\"])\n",
    "    trips_df[\"d_time\"] = pd.to_timedelta(trips_df[\"d_time\"])\n",
    "    trips_df[\"trip_duration\"] = trips_df[\"d_time\"] - trips_df[\"o_time\"]\n",
    "\n",
    "    # Add stop coordinates to stop_times\n",
    "    stop_times_ext = feed.stop_times[[\"trip_id\", \"stop_sequence\", \"stop_id\"]].merge(\n",
    "        feed.stops[[\"stop_id\", \"stop_lat\", \"stop_lon\"]], on=\"stop_id\"\n",
    "    )\n",
    "\n",
    "    # calculate approximate timestamps for each GPS trace\n",
    "    # TODO: I think this big merge can be avoided\n",
    "    trip_shape = pd.merge(\n",
    "        trips_df[[\"trip_id\", \"shape_id\", \"o_time\", \"d_time\"]],\n",
    "        matched_shapes_df,\n",
    "        how=\"left\",\n",
    "        on=\"shape_id\",\n",
    "    )\n",
    "    trip_shape = trip_shape.sort_values(\n",
    "        by=[\"trip_id\", \"shape_dist_traveled\"]\n",
    "    ).reset_index(drop=True)\n",
    "    trip_shapes_list = [item for _, item in trip_shape.groupby(\"trip_id\")]\n",
    "\n",
    "    # Attach stops to shape traces. Note that this just adds a dummy variable column\n",
    "    # indicating whether or not a stop is located at a given point on the shape.\n",
    "    if add_stop_flag:\n",
    "        attach_stop_partial = partial(\n",
    "            add_stop_flags_to_shape, stop_times_ext=stop_times_ext\n",
    "        )\n",
    "        with mp.Pool(n_processes) as pool:\n",
    "            trip_shapes_list = pool.map(attach_stop_partial, trip_shapes_list)\n",
    "\n",
    "    # Attach timestamps to each trip. These are simply based on the scheduled trip\n",
    "    # duration and shape_dist_traveled, assuming a constant speed for the entire trip.\n",
    "    # TODO: improve timestamp estimates\n",
    "    with mp.Pool(n_processes) as pool:\n",
    "        trips_with_timestamps_list = pool.map(\n",
    "            estimate_trip_timestamps, trip_shapes_list\n",
    "        )\n",
    "    logger.info(\"Finished attaching timestamps\")\n",
    "    return pd.concat(trips_with_timestamps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ec510e8-4ecf-48fc-9025-dbe03b35ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_trip_timestamps(trip_shape_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Estimate timestamps for each shape point of a trip based on distance traveled.\n",
    "\n",
    "    Args:\n",
    "        trip_shape_df (pd.DataFrame): DataFrame containing trip shape data with columns:\n",
    "            - 'shape_dist_traveled': Cumulative distance traveled along the shape.\n",
    "            - 'o_time': Origin time (datetime) of the trip.\n",
    "            - 'd_time': Destination time (datetime) of the trip.\n",
    "    Returns:\n",
    "        pd.DataFrame: Modified DataFrame with additional columns:\n",
    "            - 'segment_duration_delta': Estimated duration for each segment as timedelta.\n",
    "            - 'timestamp': Estimated timestamp for each segment.\n",
    "            - 'Datetime_nearest5': Timestamp rounded to the nearest 5 minutes.\n",
    "            - 'hour': Hour component of the rounded timestamp.\n",
    "            - 'minute': Minute component of the rounded timestamp.\n",
    "    \"\"\"\n",
    "    trip_shape_df[\"segment_duration_delta\"] = (\n",
    "        trip_shape_df[\"shape_dist_traveled\"]\n",
    "        / (trip_shape_df[\"shape_dist_traveled\"].max()+0.0001)\n",
    "        * (trip_shape_df[\"d_time\"] - trip_shape_df[\"o_time\"])\n",
    "    )\n",
    "    trip_shape_df[\"segment_duration_delta\"] = trip_shape_df[\n",
    "        \"segment_duration_delta\"\n",
    "    ].apply(lambda x: datetime.timedelta(seconds=round(x.total_seconds())))\n",
    "    trip_shape_df[\"timestamp\"] = (\n",
    "        trip_shape_df[\"o_time\"] + trip_shape_df[\"segment_duration_delta\"]\n",
    "    )\n",
    "\n",
    "    ## get hour and minute of gps timestamp\n",
    "    trip_shape_df[\"Datetime_nearest5\"] = trip_shape_df[\"timestamp\"].dt.round(\"5min\")\n",
    "    trip_shape_df[\"hour\"] = trip_shape_df[\"Datetime_nearest5\"].dt.components[\"hours\"]\n",
    "    trip_shape_df[\"minute\"] = trip_shape_df[\"Datetime_nearest5\"].dt.components[\n",
    "        \"minutes\"\n",
    "    ]\n",
    "\n",
    "    return trip_shape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd03315d-6949-44a6-aee9-ea15b26792b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by summarizing stop times: get first and last stop, plus start/end times\n",
    "stop_times_by_trip = (\n",
    "    feed.stop_times.groupby(\"trip_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"arrival_time\": \"first\",\n",
    "            \"departure_time\": \"last\",\n",
    "            \"stop_id\": [\"first\", \"last\"],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "stop_times_by_trip.columns = [\n",
    "    \"trip_id\",\n",
    "    \"o_time\",\n",
    "    \"d_time\",\n",
    "    \"o_stop_id\",\n",
    "    \"d_stop_id\",\n",
    "]\n",
    "\n",
    "# Add start/end times and stops to trips DF\n",
    "# TODO: consider doing this with gtfsblocks add_trip_data()\n",
    "trips_df = pd.merge(trips_df_2, stop_times_by_trip, how=\"left\", on=\"trip_id\")\n",
    "trips_df[\"o_time\"] = pd.to_timedelta(trips_df[\"o_time\"])\n",
    "trips_df[\"d_time\"] = pd.to_timedelta(trips_df[\"d_time\"])\n",
    "trips_df[\"trip_duration\"] = trips_df[\"d_time\"] - trips_df[\"o_time\"]\n",
    "\n",
    "# Add stop coordinates to stop_times\n",
    "stop_times_ext = feed.stop_times[[\"trip_id\", \"stop_sequence\", \"stop_id\"]].merge(\n",
    "    feed.stops[[\"stop_id\", \"stop_lat\", \"stop_lon\"]], on=\"stop_id\"\n",
    ")\n",
    "\n",
    "# calculate approximate timestamps for each GPS trace\n",
    "# TODO: I think this big merge can be avoided\n",
    "trip_shape = pd.merge(\n",
    "    trips_df[[\"trip_id\", \"shape_id\", \"o_time\", \"d_time\"]],\n",
    "    matched_shapes_df,\n",
    "    how=\"left\",\n",
    "    on=\"shape_id\",\n",
    ")\n",
    "trip_shape = trip_shape.sort_values(\n",
    "    by=[\"trip_id\", \"shape_dist_traveled\"]\n",
    ").reset_index(drop=True)\n",
    "trip_shapes_list = [item for _, item in trip_shape.groupby(\"trip_id\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b0c4a9dd-ff59-4dd8-a066-32331ba52591",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_with_timestamps_list = []\n",
    "for i in range(len(trip_shapes_list)):\n",
    "    trip_shapes_df = trip_shapes_list[i]\n",
    "    trips_with_timestamps_df = estimate_trip_timestamps(trip_shapes_df)\n",
    "    trips_with_timestamps_list.append(trips_with_timestamps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9645158-b77e-47a6-bc0a-3a9d349ec0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df_ext = pd.concat(trips_with_timestamps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "804caae3-5f8f-45f8-843a-7d1a074b5177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['226466', '226467', '5171000_to_5170972', '5171001_to_5170974',\n",
       "       '5171002_to_5170975', '5171003_to_5170976', '5171004_to_5170977',\n",
       "       '5171006_to_5170979', '5171007_to_5170980', '5171008_to_5170981',\n",
       "       '5171009_to_5170982', '5171010_to_5170983', '5171011_to_5170984',\n",
       "       '5171013_to_5170986', '5171014_to_5170987', '5171015_to_5170988',\n",
       "       '5171016_to_5170989', '5171017_to_5170990', '5171018_to_5170991',\n",
       "       '5171020_to_5170992', '5171021_to_5170993', '5171022_to_5170994',\n",
       "       '5171023_to_5170995', '5171024_to_5170996', '5171025_to_5170997',\n",
       "       'to_depot_1155704', '5171026_to_5170998', 'to_depot_1155700',\n",
       "       'to_depot_1155705', 'to_depot_1155701', 'to_depot_1155702',\n",
       "       'to_depot_1155703', 'from_depot_1155702', 'from_depot_1155703',\n",
       "       'from_depot_1155704', 'from_depot_1155700', 'from_depot_1155705',\n",
       "       'from_depot_1155701'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_df_ext['shape_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1271dcd-e6f7-417f-8397-a26d48e6080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data at road link level to reduce computational burden\n",
    "trip_links_df = (\n",
    "    trips_df_ext.groupby(by=[\"trip_id\", \"shape_id\", \"road_id\"])\n",
    "    .agg(\n",
    "        start_lat=pd.NamedAgg(\"shape_pt_lat\", \"first\"),\n",
    "        start_lon=pd.NamedAgg(\"shape_pt_lon\", \"first\"),\n",
    "        end_lat=pd.NamedAgg(\"shape_pt_lat\", \"last\"),\n",
    "        end_lon=pd.NamedAgg(\"shape_pt_lon\", \"last\"),\n",
    "        geom=pd.NamedAgg(\"geom\", \"first\"),\n",
    "        start_timestamp=pd.NamedAgg(\"timestamp\", \"first\"),\n",
    "        end_timestamp=pd.NamedAgg(\"timestamp\", \"last\"),\n",
    "        kilometers=pd.NamedAgg(\"kilometers\", \"mean\"),\n",
    "        travel_time_minutes=pd.NamedAgg(\"travel_time\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "trip_links_df[\"travel_time_minutes\"] /= 60\n",
    "trips_df_list = [t_df for _, t_df in trip_links_df.groupby(\"trip_id\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c8a2554-da20-4b96-ba80-bdb891e70bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trips_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23161666-07e8-49dd-ae1c-f9aa4c1bac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/Users/yhe/github_repo/routee-transit/nrel/routee/transit/prediction/grade/add_grade.py:Running gradeit on 68 trips with 10 processes.\n",
      "2025-10-22 09:44:44,434 [INFO] - Running gradeit on 68 trips with 10 processes.\n",
      "INFO:nrel.routee.transit.prediction.grade.download:Downloading 1 USGS tiles at ONE_THIRD_ARC_SECOND resolution.\n",
      "2025-10-22 09:44:44,667 [INFO] - Downloading 1 USGS tiles at ONE_THIRD_ARC_SECOND resolution.\n",
      "INFO:nrel.routee.transit.prediction.grade.download:downloading n41w112\n",
      "2025-10-22 09:44:45,322 [INFO] - downloading n41w112\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  grade = d_elev / distances\n",
      "/Users/yhe/.pyenv/versions/3.12.0/lib/python3.12/site-packages/gradeit/grade.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  grade = d_elev / distances\n"
     ]
    }
   ],
   "source": [
    "add_road_grade = True\n",
    "tile_resolution = TileResolution.ONE_THIRD_ARC_SECOND\n",
    "n_processes = mp.cpu_count()\n",
    "if add_road_grade:\n",
    "    result_df = run_gradeit_parallel(\n",
    "        trip_dfs_list=trips_df_list,\n",
    "        tile_resolution=tile_resolution,\n",
    "        n_processes=n_processes,\n",
    "    )\n",
    "else:\n",
    "    result_df = pd.concat(trips_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40e24636-f074-4863-a9b3-ba6a285e6079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['226466', '226467', 'to_depot_1155704', 'to_depot_1155700',\n",
       "       'to_depot_1155705', 'to_depot_1155701', 'to_depot_1155702',\n",
       "       'to_depot_1155703', 'from_depot_1155702', 'from_depot_1155703',\n",
       "       'from_depot_1155704', 'from_depot_1155700', 'from_depot_1155705',\n",
       "       'from_depot_1155701'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['shape_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87179c82-6355-4342-a32d-7b0329b0b072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
